defaults:
  - override /hydra/launcher: joblib

model:
  hubert_model_name: "facebook/hubert-base-ls960"
  hubert_layer: 6
  adapter_hidden_dim: 1024

dataset:
  path_pattern: "/workspace/dataset/noisy_clean_pairs/{000000..000010}.tar"
  val_path_pattern: "/workspace/dataset/noisy_clean_pairs_valid/{000000..000001}.tar"
  shuffle: true

batch_size: 8
loader:
  num_workers: 2
  pin_memory: true

gradient_accumulation_steps: 2

adapter_ckpt: "/workspace/outputs/adapter_layer_6/pytorch_model.bin"
pretrained_gen: "/workspace/outputs/hifigan_pretrain_layer_6/pytorch_model.bin"

# ----- Generator アーキテクチャ -----
upsample_rates:        [8, 8, 2, 2]
upsample_kernel_sizes: [16, 16, 4, 4]
resblock_kernel_sizes: [3, 7, 11]
resblock_dilations: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]

# ----- 学習ハイパーパラメータ -----
steps: 50000
validation_interval: 2500
validation_batches: 25
lr: 1e-4
betas: [0.8, 0.99]
seed: 42
lambda_stft: 1.0
lambda_mpd: 2.5
lambda_msd: 2.5

save_dir: "/workspace/outputs/hifigan_finetune_layer_6"
log_interval: 100
audio_log_interval: 2500

# Checkpoint configuration
checkpoint:
  save_interval: 5000
  resume_from: null        # 再開用チェックポイントパス
  keep_last_n: 10
  save_wandb_metadata: true # wandb情報も保存

# Wandb logging configuration
wandb:
  enabled: true
  project: "miipher-2"
  entity: "your_wandb_entity"
  name: "hifigan_finetune_layer_6"
  tags: ["hifigan", "vocoder", "finetune"]
  notes: "HiFi-GAN fine-tuning for Miipher-2"
  log_model: true
  log_audio: true          # 音声サンプルをログ

# Accelerate training settings
training:
  mixed_precision: "fp16"
  force_cpu: false
  gradient_accumulation_steps: ${gradient_accumulation_steps}

# Accelerate configuration options
accelerate:
  # FSDP (Fully Sharded Data Parallel) settings
  fsdp:
    enabled: false
    min_num_params: 0
    transformer_layer_cls_to_wrap: ""
    backward_prefetch: "backward_pre"
    forward_prefetch: false
    use_orig_params: true

  # DeepSpeed settings
  deepspeed:
    enabled: false
    config_file: null
