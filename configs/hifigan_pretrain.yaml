model:
  hubert_model_name: "rinna/japanese-hubert-large"
  hubert_layer: 12
  # 事前学習ではAdapterは使用しない
  adapter_hidden_dim: null

dataset:
  # Webdatasetは共通ですが、ローダー側でクリーンな音声のみを利用します
  path_pattern: /home/ayu/datasets/jvs_preprocessed/jvs-train-{000000..000020}.tar.gz
  shuffle: 1000

batch_size: 1
loader:
  num_workers: 8
  pin_memory: true

# 事前学習では学習済みAdapterは不要
adapter_ckpt: null

# この事前学習ステージでは、公式の事前学習済みモデルをベースに学習します
pretrained_gen: assets/universal_hifigan_v1/g_02500000

# ----- Generator アーキテクチャ -----
upsample_rates:        [8, 8, 2, 2]
upsample_kernel_sizes: [16, 16, 4, 4]
resblock_kernel_sizes: [3, 7, 11]
resblock_dilations: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]

# ----- 学習ハイパーパラメータ -----
# 事前学習用のステップ数（必要に応じて調整してください）
steps: 100000
lr: 2.0e-4
betas: [0.9, 0.95]
lambda_stft: 1.0 # この値はhifigan_finetune.yamlにはありませんが、学習スクリプトで参照されるため念のため記載
lambda_mpd: 2.5  # 同上
lambda_msd: 2.5  # 同上

# チェックポイントの保存先を事前学習用に変更
save_dir: exp/hifigan_pretrain
log_interval: 10

# Checkpoint configuration
checkpoint:
  save_interval: 1000
  resume_from: null
  keep_last_n: 5
  save_wandb_metadata: true

# Wandb logging configuration
wandb:
  enabled: true
  # プロジェクト名を事前学習用に変更
  project: "miipher-2-hifigan-pretrain"
  entity: null
  name: null
  tags: ["hifigan", "vocoder", "pretrain"]
  notes: "HiFi-GAN pre-training on clean HuBERT features"
  log_model: true
  log_audio: true
