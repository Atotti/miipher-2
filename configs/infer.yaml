# --- 推論の基本設定 ---
input_wav: "/home/ayu/GitHub/miipher-plaoground/samples_8khz/F001_R1_E2_M2_AA.wav"
output_wav: "/home/ayu/GitHub/miipher-plaoground/open_miipher_2/F001_R1_E2_M2_AA.wav"
device: "cuda" # "cuda" または "cpu"

# --- チェックポイントのパス ---
# Adapter学習で生成された最終モデル
adapter_ckpt: "exp/adapter_layer_4_mhubert_147/checkpoint_159k.pt"

# HiFi-GAN Fine-tuningで生成されたチェックポイント
vocoder_ckpt: "exp/hifigan_pretrain_layer_4_mhubert_147/checkpoint_96k.pt"


# --- モデル設定 (Fine-tuning時と一致させる) ---
model:
  hubert_model_name: "utter-project/mHuBERT-147"
  hubert_layer: 4
  adapter_hidden_dim: 768

# --- Vocoder設定 ---
# Prenetのパラメータ (hifigan.pyの実装に合わせる)
prenet:
  in_dim: 768     # HuBERTの出力次元数と一致
  n_layers: 4
  mel_dim: 80
  src_fps: 50.0
  tgt_hop: 256
  sr: 22050

# Generatorのconfigはvocoder_ckptと同じディレクトリのconfig.jsonから自動で読み込まれます

# --- 出力設定 ---
output_sampling_rate: 22050
