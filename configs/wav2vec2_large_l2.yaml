model:
  hubert_model_name: "facebook/wav2vec2-large-xlsr-53"  # SSLモデル名
  hubert_layer: 2
  adapter_hidden_dim: 1024  # Adapterの中間層の次元数
  model_type: "wav2vec2"  # モデルタイプを明示的に指定

dataset:
  path_pattern:
    - /home/ayu/datasets/jvs_preprocessed/jvs-train-{000000..000025}.tar.gz
  val_path_pattern:
    - /home/ayu/datasets/jvs_preprocessed/jvs-val-{000000..000001}.tar.gz
  shuffle: 1000          # WebDataset 内部 shuffle バッファ
batch_size: 8
steps: 200000
validation_interval: 500
validation_batches: 1

training:
  gradient_accumulation_steps: 1
  mixed_precision: "no"
  dataloader_drop_last: true

optim:
  lr: 2.0e-4
  weight_decay: 0.01
  betas: [0.9, 0.95]
  max_grad_norm: 1.0
  scheduler:
    name: "constant_with_warmup"
    warmup_steps: 100

loader:
  num_workers: 8
  pin_memory: true

save_dir: exp/wav2vec2_large_l2
log_interval: 100        # iter ごとに損失表示

# Checkpoint configuration
checkpoint:
  save_interval: 1000      # 1kステップごとにチェックポイント保存
  resume_from: null        # 再開用チェックポイントパス
  keep_last_n: 500          # 最新N個のチェックポイントを保持
  save_wandb_metadata: true # wandb情報も保存

# Wandb logging configuration
wandb:
  enabled: true
  project: "miipher-2-adapter"
  entity: null             # デフォルトのwandbエンティティを使用
  name: null               # 実行名を自動生成
  tags: ["wav2vec2", "adapter", "training"]
  notes: "Parallel Adapter training for Miipher-2"
  log_model: false
