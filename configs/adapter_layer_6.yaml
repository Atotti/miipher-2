model:
  hubert_model_name: "rinna/japanese-hubert-large"  # HuBERTベースモデル名
  hubert_layer: 6          # 使用するHuBERTの層（0-based）
  adapter_hidden_dim: 1024  # Adapterの中間層の次元数

dataset:
  path_pattern: /home/ayu/datasets/jvs_preprocessed/jvs-train-{000000..000020}.tar.gz
  val_path_pattern: /home/ayu/datasets/jvs_preprocessed/jvs-val-{000000..000001}.tar.gz
  shuffle: 1000          # WebDataset 内部 shuffle バッファ
batch_size: 8
steps: 60000
validation_interval: 1000
validation_batches: 25
seed: 42  # 乱数シード

# Accelerate training configuration
training:
  gradient_accumulation_steps: 2
  mixed_precision: "fp16"      # "no" / "fp16" / "bf16" - AccelerateでAMP使用
  force_cpu: false             # CPUに強制する場合のみtrue

optim:
  lr: 2.0e-4
  weight_decay: 0.01
  betas: [0.9, 0.95]
  max_grad_norm: 1.0
  scheduler:
    name: "constant_with_warmup"
    warmup_steps: 100

loader:
  num_workers: 8
  pin_memory: true

save_dir: exp/adapter_layer_6
log_interval: 100        # iter ごとに損失表示

# Checkpoint configuration
checkpoint:
  save_interval: 1000      # 1kステップごとにチェックポイント保存
  resume_from: null        # 再開用チェックポイントパス
  keep_last_n: 500          # 最新N個のチェックポイントを保持
  save_wandb_metadata: true # wandb情報も保存

# Wandb logging configuration (Accelerateトラッカー使用)
wandb:
  enabled: true
  project: "miipher-2-adapter"
  entity: null             # デフォルトのwandbエンティティを使用
  name: null               # 実行名を自動生成
  tags: ["hubert", "adapter", "training", "accelerate"]
  notes: "Accelerate-based Parallel Adapter training for Miipher-2"
  log_model: false
  log_audio: false         # 音声サンプルをログするかどうか
  id: null                 # 固定IDで再開する場合のWandB run ID

# Accelerate固有設定
accelerate:
  fsdp: null               # FSDP設定（大規模モデルの場合）
  deepspeed: null          # DeepSpeed設定
  dataloader_config:
    split_batches: false   # バッチを分割するかどうか
    dispatch_batches: null # バッチのディスパッチ方法
