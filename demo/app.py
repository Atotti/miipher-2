import gradio as gr
import torch
import numpy as np
import pathlib
from omegaconf import DictConfig
import librosa
from huggingface_hub import hf_hub_download
import os

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ãƒ•ãƒ©ã‚°
_models_loaded = False
_cleaner = None
_vocoder = None
_device = None

def download_models():
    """Hugging Face Hubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        print("Downloading models from Hugging Face Hub...")
        
        # Adapter model
        adapter_path = hf_hub_download(
            repo_id="Atotti/miipher-2-HuBERT-HiFi-GAN-v0.1",
            filename="checkpoint_199k_fixed.pt",
            cache_dir="./models"
        )
        
        # Vocoder model  
        vocoder_path = hf_hub_download(
            repo_id="Atotti/miipher-2-HuBERT-HiFi-GAN-v0.1",
            filename="epoch=77-step=137108.ckpt",
            cache_dir="./models"
        )
        
        return adapter_path, vocoder_path
        
    except Exception as e:
        print(f"Model download failed: {e}")
        return None, None

def load_models():
    """ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€åº¦ã ã‘èª­ã¿è¾¼ã‚€"""
    global _models_loaded, _cleaner, _vocoder, _device
    
    if _models_loaded:
        return
    
    try:
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        _device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # FeatureCleaner
        from miipher_2.model.feature_cleaner import FeatureCleaner
        from miipher_2.lightning_vocoders.lightning_module import HiFiGANLightningModule
        
        # è¨­å®šã‚’è¾æ›¸ã¨ã—ã¦å®šç¾©
        model_config = DictConfig({
            "hubert_model_name": "utter-project/mHuBERT-147",
            "hubert_layer": 6,
            "adapter_hidden_dim": 768
        })
        
        print("Loading FeatureCleaner model...")
        _cleaner = FeatureCleaner(model_config).to(_device).eval()
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        adapter_path, vocoder_path = download_models()
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
        local_adapter = "checkpoint_199k_fixed.pt"
        local_vocoder = "epoch=77-step=137108.ckpt"
        
        adapter_ckpt_path = adapter_path if adapter_path else local_adapter
        vocoder_ckpt_path = vocoder_path if vocoder_path else local_vocoder
        
        if pathlib.Path(adapter_ckpt_path).exists():
            adapter_checkpoint = torch.load(adapter_ckpt_path, map_location=_device, weights_only=False)
            _cleaner.load_state_dict(adapter_checkpoint["model_state_dict"])
            print("FeatureCleaner model loaded.")
        else:
            print("âš ï¸ Adapter checkpoint not found. Running without trained adapter.")
        
        # Vocoder
        if pathlib.Path(vocoder_ckpt_path).exists():
            print("Loading Lightning SSL-Vocoder...")
            _vocoder = HiFiGANLightningModule.load_from_checkpoint(
                vocoder_ckpt_path, map_location=_device
            ).to(_device).eval()
            print("Lightning SSL-Vocoder loaded.")
        else:
            print("âš ï¸ Vocoder checkpoint not found. Cannot generate audio.")
            _vocoder = None
        
        _models_loaded = True
        
    except Exception as e:
        print(f"Model loading failed: {e}")
        # ãƒ‡ãƒ¢ç”¨ã«ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
        _cleaner = None
        _vocoder = None
        _models_loaded = True

def process_audio(input_audio):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ä¿®å¾©ã•ã‚ŒãŸéŸ³å£°ã‚’è¿”ã™"""
    if input_audio is None:
        return None, "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    try:
        # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        load_models()
        
        if _cleaner is None or _vocoder is None:
            return None, "âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã“ã‚Œã¯ãƒ‡ãƒ¢ç‰ˆã§ã™ã€‚"
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆGradioã¯(sample_rate, audio_data)ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ï¼‰
        sample_rate, audio_data = input_audio
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’float32ã«å¤‰æ›ã—ã€æ­£è¦åŒ–
        if audio_data.dtype == np.int16:
            audio_data = audio_data.astype(np.float32) / 32768.0
        elif audio_data.dtype == np.int32:
            audio_data = audio_data.astype(np.float32) / 2147483648.0
        
        # ã‚¹ãƒ†ãƒ¬ã‚ªã®å ´åˆã¯ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
        if len(audio_data.shape) > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        # 22050Hzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if sample_rate != 22050:
            audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=22050)
        
        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        input_wav = torch.from_numpy(audio_data).unsqueeze(0).to(_device)
        
        # æ¨è«–å®Ÿè¡Œ
        with torch.inference_mode():
            with torch.autocast(device_type=_device.type, dtype=torch.float16, enabled=(_device.type == "cuda")):
                cleaned_features = _cleaner(input_wav)
                batch = {"input_feature": cleaned_features.transpose(1, 2)}
                restored_wav = _vocoder.generator_forward(batch)
        
        # å‡ºåŠ›éŸ³å£°ã‚’æº–å‚™
        output_audio = restored_wav.squeeze(0).cpu().to(torch.float32).numpy()
        
        return (22050, output_audio), "âœ… éŸ³å£°ä¿®å¾©ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
        
    except Exception as e:
        return None, f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def create_demo():
    """Gradioãƒ‡ãƒ¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆ"""
    
    with gr.Blocks(title="Miipher-2 éŸ³å£°ä¿®å¾©ãƒ‡ãƒ¢", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸµ Miipher-2 éŸ³å£°ä¿®å¾©ãƒ‡ãƒ¢
        
        ã“ã®ãƒ‡ãƒ¢ã¯ã€Miipher-2ã‚’ä½¿ç”¨ã—ã¦åŠ£åŒ–ã—ãŸéŸ³å£°ã‚’ä¿®å¾©ã—ã¾ã™ã€‚
        
        **ä½¿ç”¨æ–¹æ³•:**
        1. ãƒã‚¤ã‚¯ã‹ã‚‰éŒ²éŸ³ã™ã‚‹ã‹ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
        2. ã€ŒéŸ³å£°ã‚’ä¿®å¾©ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„
        3. ä¿®å¾©ã•ã‚ŒãŸéŸ³å£°ãŒä¸‹éƒ¨ã«è¡¨ç¤ºã•ã‚Œã¾ã™
        
        **ãƒ¢ãƒ‡ãƒ«æƒ…å ±:**
        - ãƒ¢ãƒ‡ãƒ«ã¯Hugging Face Hubã‹ã‚‰è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™
        - Model: [Atotti/miipher-2-HuBERT-HiFi-GAN-v0.1](https://huggingface.co/Atotti/miipher-2-HuBERT-HiFi-GAN-v0.1)
        - çµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆAdapter + Vocoderï¼‰ã‚’ä½¿ç”¨
        """)
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ“¤ å…¥åŠ›éŸ³å£°")
                input_audio = gr.Audio(
                    label="éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯éŒ²éŸ³",
                    type="numpy",
                    format="wav"
                )
                
                process_btn = gr.Button("ğŸ”§ éŸ³å£°ã‚’ä¿®å¾©", variant="primary", size="lg")
                
            with gr.Column():
                gr.Markdown("### ğŸ“¥ ä¿®å¾©ã•ã‚ŒãŸéŸ³å£°")
                output_audio = gr.Audio(
                    label="ä¿®å¾©ã•ã‚ŒãŸéŸ³å£°",
                    type="numpy",
                    format="wav"
                )
                
                status_text = gr.Textbox(
                    label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                    interactive=False,
                    lines=2
                )
        
        # ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        gr.Markdown("""
        ### ğŸ“š æŠ€è¡“æƒ…å ±
        
        **Miipher-2** ã¯ä»¥ä¸‹ã®æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼š
        - **SSLç‰¹å¾´æŠ½å‡º**: mHuBERT-147 (6å±¤ç›®ã®ç‰¹å¾´ã‚’ä½¿ç”¨)
        - **Parallel Adapter**: è»½é‡ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        - **Lightning SSL-Vocoder**: HiFi-GANãƒ™ãƒ¼ã‚¹ã®éŸ³å£°åˆæˆ
        
        **å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: WAV, MP3, FLAC (22050Hzæ¨å¥¨)
        """)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
        process_btn.click(
            fn=process_audio,
            inputs=[input_audio],
            outputs=[output_audio, status_text]
        )
        
        # ã‚µãƒ³ãƒ—ãƒ«ä¾‹ã®è¿½åŠ 
        with gr.Row():
            gr.Examples(
                examples=[],  # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã“ã“ã«è¿½åŠ 
                inputs=[input_audio],
                outputs=[output_audio, status_text],
                fn=process_audio,
                cache_examples=False
            )
    
    return demo

if __name__ == "__main__":
    demo = create_demo()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )